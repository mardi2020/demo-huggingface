{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.12/site-packages (0.21.0)\r\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.12/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.5)\r\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2024.9.0)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (75.8.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from torchvision) (2.2.2)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (11.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:39.382710Z",
     "start_time": "2025-02-09T13:14:38.202528Z"
    }
   },
   "id": "19173f7c36dd5ed0",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "# torch 가 정상적으로 설치되었는지 확인하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74bffa931986d51c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # 설치된 PyTorch 버전 출력\n",
    "print(torch.cuda.is_available())  # GPU 사용 가능 여부 출력 (True면 GPU 사용 가능)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:39.386181Z",
     "start_time": "2025-02-09T13:14:39.384080Z"
    }
   },
   "id": "f702355005e7def2",
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AutoModel 클래스로 id에 맞는 모델 가져오기\n",
    "\n",
    "model_id를 허깅페이스 모델 허브의 저장소 경로 혹은 로컬 경로 지정해서 모델 불러올 수 있다.\n",
    "RoBERTa는 구글의 BERT를 개선한 모델이고, 여기서 사용하는 모델은 RoBERTa 모델을 한국어로 학습한 모델이다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "645291d58f8ae7cc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model_id = 'klue/roberta-base'\n",
    "model = AutoModel.from_pretrained(model_id)\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:39.882866Z",
     "start_time": "2025-02-09T13:14:39.386704Z"
    }
   },
   "id": "initial_id",
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AutoModel 클래스\n",
    "어떻게 `klue/roberta-base` 저장소의 모델이 RoBERTa 계열의 모델인지 알 수 있을까?\n",
    "- 허깅페이스 모델을 저장할 때 config.json 파일이 함께 저장되는데 해당 파일에는 model_type, 여러 설정 파라미터(num_attention_heads 등), 어휘 사전 크기(vocab_size), tokenizer_class 등이 저장됨\n",
    "\n",
    "AutoModel과 AutoTokenizer 클래스는 config.json을 참고해 적절한 모델과 토크나이저를 불러온다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de8a61ed3729d996"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 텍스트 분류 헤드가 붙은 모델 불러오기\n",
    "\n",
    "`SamLowe/roberta-base-go_emotions` 모델: 분류 헤드가 포함되어 있으며 입력 문장이 어떤 감성을 나타내는지 분류함(ex: admiration, amusement, anger etc...)\n",
    "`AutoModelForSequenceClassification`: 텍스트 시퀀스 분류를 위한 헤드가 포함된 모델을 불러올 때 사용하는 클래스"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea8a606fc2890898"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_id = 'SamLowe/roberta-base-go_emotions'\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.129419Z",
     "start_time": "2025-02-09T13:14:39.884187Z"
    }
   },
   "id": "80b5e721682500c6",
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 텍스트 분류를 위한 아키텍처에 모델 바디만 불러오기\n",
    "AutoModelForSequenceClassification 클래스를 사용하면 분류 헤드가 붙은 모델을 불러올 수 있다.\n",
    "이 클래스를 사용해 모델 바디 부분의 파라미터만 있는 `klue/roberta-base` 모델을 불러온다면, 아래와 같은 경고가 발생한다.\n",
    "- ⚠️경고 내용: 모델의 바디 부분은 `klue/roberta-base`의 사전학습된 파라미터를 불러왔으나 `klue/roberta-base` 모델 허브에서는 분류 헤드에 대한 파라미터를 찾을 수 없어 랜덤!!으로 초기화 했다는 내용\n",
    "- ⚠️분류 헤드가 랜덤으로 초기화되었기 때문에 그대로 사용하면 안되고 추가 학습 이후에 사용하라고 안내됨\n",
    "\n",
    "분류 헤드가 학습되지 않았기 때문에 의미 있는 분류를 할 수 없음, 그렇다면 어떻게 분류 헤드를 학습해 분류 모델을 만들 수 있을까?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "402119a4954a38b1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_id = 'klue/roberta-base'\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.363474Z",
     "start_time": "2025-02-09T13:14:40.130045Z"
    }
   },
   "id": "1fe4ed26e53691c0",
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 토크나이저 활용\n",
    "\n",
    "⭐️토크나이저: 텍스트를 토큰 단위로 나누고 각 토큰을 대응하는 토큰 아이디로 변환, 필요한경우 특수 토큰을 추가하는 역할\n",
    "토크나이저도 학습 데이터를 통해 어휘 사전을 구축하므로 일반적으로 모델과 함께 저장됨\n",
    "\n",
    "허깅페이스 허브에서 모델과 토크나이저를 불러올때 동일한 모델 아이디로 맞춰야함!!\n",
    "\n",
    "- tokenizer_config.json: 토크나이저의 종류나 설정에 대한 정보를 갖고 있음\n",
    "- tokenizer.json: 실제 어휘 사전 정보를 갖고 있음"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "174f68fc1924e438"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = 'klue/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.591904Z",
     "start_time": "2025-02-09T13:14:40.364206Z"
    }
   },
   "id": "930f6de0dfde1900",
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 토크나이저 예제\n",
    "\n",
    "tokenizer(\"문장\")\n",
    "- input_ids: 토큰 아이디의 리스트\n",
    "- attention_mask: 토큰이 실제 텍스트인지 아니면 길이를 맞추기 위해 추가한 padding인지 알려줌\n",
    "- token_type_ids: 토큰이 속한 문장의 아이디를 알려줌"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f773a1d3db1a801a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids [0, 9157, 7461, 2190, 2259, 8509, 2138, 1793, 2855, 5385, 2200, 20950, 2]\n",
      "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer(\"토크나이저는 텍스트를 토큰 단위로 나눈다\")\n",
    "\n",
    "for k, v in tokenized.items():\n",
    "    print(k, v)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.594455Z",
     "start_time": "2025-02-09T13:14:40.592499Z"
    }
   },
   "id": "806546eed13e77f8",
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "source": [
    "- input_ids: 토큰화했을 때 각 토큰이 토크나이저 사전의 몇번째 항목인지 나타냄\n",
    "input_ids에서 첫번째 항목은 0이고 두번째 항목은 9157인데, 각각 [CLS]와 '토크'에 대응되는 것을 확인할 수 있음\n",
    "- attention_mask[idx] == 1: 실제 토큰 else 패딩\n",
    "\n",
    "token_type_ids[idx] == 0: 일반적으로 첫번째 문장임"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dd3d756ba68a227"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '토크', '##나이', '##저', '##는', '텍스트', '##를', '토', '##큰', '단위', '##로', '나눈다', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(tokenized['input_ids']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.596591Z",
     "start_time": "2025-02-09T13:14:40.594973Z"
    }
   },
   "id": "e0e1a52df42564e2",
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "토큰 아이디를 다시 텍스트로 돌리고 싶다면 토크나이저의 `decode` 메서드 사용\n",
    "- 특수 토큰이 추가됨을 확인할 수 있음\n",
    "    - [CLS]\n",
    "    - [SEP]\n",
    "- skip_special_tokens=True 시 특수 토큰 스킵"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10de9890cd1db8bb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 토크나이저는 텍스트를 토큰 단위로 나눈다 [SEP]\n",
      "토크나이저는 텍스트를 토큰 단위로 나눈다\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized['input_ids']))\n",
    "print(tokenizer.decode(tokenized['input_ids'], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.598925Z",
     "start_time": "2025-02-09T13:14:40.597174Z"
    }
   },
   "id": "dee1d24ce9acce0e",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[0, 5891, 2205, 5971, 35, 2], [0, 13472, 10211, 2036, 16, 30520, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이저에 여러 문장을 넣을수도 있다.\n",
    "tokenizer(['안녕하세요?', 'Hello, world'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.602571Z",
     "start_time": "2025-02-09T13:14:40.600491Z"
    }
   },
   "id": "405e5256536b04bf",
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "한 번에 여러 문장을 모델에 넣어야 하는 경우가 있음\n",
    "\n",
    "예를 들어, 2개의 문장이 서로 원인/결과 관계인지 학습시키고 싶을 때\n",
    "- 이 경우, 2개의 문장이 하나의 데이터라는 것을 표시하기 위해 아래처럼 리스트로 한번 더 감싼다"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1007bc699f68c58d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[0, 5891, 2205, 5971, 35, 2, 13472, 10211, 2036, 16, 30520, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([['안녕하세요?', 'Hello, world']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.604743Z",
     "start_time": "2025-02-09T13:14:40.603043Z"
    }
   },
   "id": "4530ef09b87152e1",
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "source": [
    "tokenizer의 batch_decode() 메서드\n",
    "- input_ids 부분의 토큰 아이디를 문자열로 복원\n",
    "- 2개의 문장을 한번에 토큰화할 경우, [SEP]으로 두 문장을 구분함\n",
    "- 특수 토큰은 모델의 아키텍처에 따라 달라질 수 있음"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9453474e9852acc6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS] 첫번째 문장 [SEP]', '[CLS] 두번째 문장 [SEP]']"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_tokenized_result = tokenizer(['첫번째 문장', '두번째 문장'])['input_ids']\n",
    "tokenizer.batch_decode(first_tokenized_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.607720Z",
     "start_time": "2025-02-09T13:14:40.605338Z"
    }
   },
   "id": "f2d3397469550087",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS] 첫번째 문장 [SEP] 두번째 문장 [SEP]']"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_tokenized_result = tokenizer([['첫번째 문장', '두번째 문장']])['input_ids']\n",
    "tokenizer.batch_decode(second_tokenized_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.610251Z",
     "start_time": "2025-02-09T13:14:40.608260Z"
    }
   },
   "id": "9d9cfb98173e94c1",
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "### token_type_ids: 문장을 구분하는 역할\n",
    "\n",
    "BERT는 학습할때 2개의 문장이 서로 이어지는지 맞추는 NST(Next Sentence prediction) 작업을 활용, 이를 위해 문장을 구분하는 토큰 타입 아이디를 만듦\n",
    "그래서 BERT의 토크나이저를 불러오면, 문장에 따라 토큰 타입 아이디를 구분함\n",
    "\n",
    "klue/bert-base 토크나이저를 사용하면 첫번째 문장의 토큰 타입 아이디는 0, 두번째 문장의 토큰 타입 아이디는 1\n",
    "klue/roberta-base의 경우, 모두 0임 -> RoBERTa 계열 모델은 NSP 작업을 학습 과정에서 제거해서 문장 토큰 구분이 필요없다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e77e4007e8879eb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[2, 1656, 2517, 3135, 6265, 3, 864, 2517, 3135, 6265, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "bert_tokenizer([['첫번째 문장', '두번째 문장']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:40.848992Z",
     "start_time": "2025-02-09T13:14:40.610724Z"
    }
   },
   "id": "2d870729e743620e",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[0, 1656, 2517, 3135, 6265, 2, 864, 2517, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
    "roberta_tokenizer([['첫번째 문장', '두번째 문장']]) # token_type_ids 가 모두 0 이다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:41.141277Z",
     "start_time": "2025-02-09T13:14:40.849586Z"
    }
   },
   "id": "d08914371d1929b8",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[0, 9502, 3645, 2, 2, 10815, 3645, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roberta-base 토크나이저로 영어 문장을 토큰화하면 결과에 token_type_ids 항목이 없다.\n",
    "en_roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "en_roberta_tokenizer([['first sentence', 'second sentence']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:41.423779Z",
     "start_time": "2025-02-09T13:14:41.141964Z"
    }
   },
   "id": "33d79b26379a8df1",
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "source": [
    "### attention_mask\n",
    "> 해당 토큰이 패딩 토큰인지 실제 데이터인지에 대한 정보를 담음\n",
    "\n",
    "패딩: 모델에 입력하는 토큰 아이디의 길이를 맞추기 위해 추가하는 특수 토큰\n",
    "- tokenizer의 padding='longest' 를 입력하면 입력한 문장 중 가장 긴 문장에 맞춰 패딩 토큰 추가"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16c2f70c23289ed"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [[0, 1656, 1141, 3135, 6265, 2073, 1599, 2062, 18, 2, 1, 1, 1, 1, 1, 1, 1], [0, 864, 1141, 3135, 6265, 2073, 1656, 1141, 3135, 6265, 2178, 2062, 831, 647, 2062, 18, 2]]\n",
      "token_type_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "두 번째 문장이 더 길기 때문에 더 긴 문장에 맞춰 패딩 토큰을 추가한다면 첫 번째 문장에 패딩이 추가됨\n",
    "input_ids에서 첫 번째 문장에 패딩 토큰(토큰 아이디 = 1)이 6개 추가됨\n",
    "attention_mask에는 패딩 토큰을 나타내는 숫자 0이 6개 붙음\n",
    "\"\"\"\n",
    "result = tokenizer(['첫 번째 문장은 짧다.', '두 번째 문장은 첫 번째 문장보다 더 길다.'], padding='longest')\n",
    "for k, v in result.items():\n",
    "    print(f'{k}: {v}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:41.426698Z",
     "start_time": "2025-02-09T13:14:41.424323Z"
    }
   },
   "id": "d58bf818fbbc2f32",
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "source": [
    "# datasets 라이브러리 활용하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9177de07ed335627"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load_dataset(): 데이터셋을 불러오는 함수(데이터셋 이름, 서브셋 이름)\n",
    "klue_mrc_dataset = load_dataset('klue', 'mrc')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:46.677352Z",
     "start_time": "2025-02-09T13:14:41.427300Z"
    }
   },
   "id": "1aa38af0e461d66c",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n        num_rows: 17554\n    })\n    validation: Dataset({\n        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n        num_rows: 5841\n    })\n})"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_mrc_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:46.680443Z",
     "start_time": "2025-02-09T13:14:46.678105Z"
    }
   },
   "id": "2df512d7247e3e19",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
      "    num_rows: 17554\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 유형이 train인 데이터만 보고 싶은 경우\n",
    "print(load_dataset('klue', 'mrc', split='train'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:50.939563Z",
     "start_time": "2025-02-09T13:14:46.681198Z"
    }
   },
   "id": "293159ae99de3975",
   "execution_count": 74
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 로컬의 데이터를 활용하는 법"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fd7a0a904441263"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# local의 csv - 로컬에 해당 데이터가 없어서 오류남 주석처리\n",
    "# dataset = load_dataset('csv', data_files=\"file.csv\")\n",
    "\n",
    "# 파이썬 딕셔너리 \n",
    "my_dict = {\"a\": [1, 2, 3]}\n",
    "dataset2 = Dataset.from_dict(my_dict)\n",
    "\n",
    "# 판다스 데이터프레임\n",
    "import  pandas as pd\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3]})\n",
    "dataset3 = Dataset.from_pandas(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:50.950001Z",
     "start_time": "2025-02-09T13:14:50.940769Z"
    }
   },
   "id": "2cc1084d7f442c2",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['a'],\n    num_rows: 3\n})"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:50.952773Z",
     "start_time": "2025-02-09T13:14:50.950569Z"
    }
   },
   "id": "1b2e2fe0273b4e6",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['a'],\n    num_rows: 3\n})"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:50.955350Z",
     "start_time": "2025-02-09T13:14:50.953238Z"
    }
   },
   "id": "335c5c3c9b3c5e84",
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 학습시키기\n",
    "한국어 기사 제목을 바탕으로 기사의 카테고리를 분류하는 텍스트 분류 모델 실습\n",
    "\n",
    "✨과정\n",
    "1. 데이터셋 준비\n",
    "2. 모델과 토크나이저를 불러와 모델 학습 - 허깅페이스 트랜스포머에서는 학습 과정을 추상화한 Trainer API를 제공(but, 내부 과정을 알 수 없음)\n",
    "3. 학습을 마친 모델을 저장하거나 공유할 수 있도록 허깅페이스 허브에 업로드"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "833bef10f20e71b7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['guid', 'title', 'label', 'url', 'date'],\n    num_rows: 45678\n})"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"klue 데이터셋의 YNAT(연합 뉴스 기사 제목과 기사가 속한 카테고리 정보 포함) 서브셋 활용\"\n",
    "KLUE, MNC = 'klue', 'ynat'\n",
    "\n",
    "klue_tc_train = load_dataset(KLUE, MNC, split='train')\n",
    "klue_tc_eval = load_dataset(KLUE, MNC, split='validation')\n",
    "klue_tc_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.009916Z",
     "start_time": "2025-02-09T13:14:50.956271Z"
    }
   },
   "id": "e4aa321303da497e",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['guid', 'title', 'label', 'url', 'date'],\n    num_rows: 9107\n})"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "guid: 데이터의 고유 ID - 불필요\n",
    "title\n",
    "label: 속한 카테고리 ID\n",
    "url - 불필요\n",
    "date - 불필요\n",
    "\"\"\"\n",
    "klue_tc_eval"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.014169Z",
     "start_time": "2025-02-09T13:14:59.011046Z"
    }
   },
   "id": "be9f8aad35254af1",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'guid': 'ynat-v1_train_00000',\n 'title': '유튜브 내달 2일까지 크리에이터 지원 공간 운영',\n 'label': 3,\n 'url': 'https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=105&sid2=227&oid=001&aid=0008508947',\n 'date': '2016.06.30. 오전 10:36'}"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.018501Z",
     "start_time": "2025-02-09T13:14:59.015170Z"
    }
   },
   "id": "beb2c300d207d289",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치']"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"데이터셋의 정보를 저장하고 있는 features 속성에서 label 컬럼의 항목별 이름 확인\"\n",
    "klue_tc_train.features['label'].names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.022007Z",
     "start_time": "2025-02-09T13:14:59.019378Z"
    }
   },
   "id": "8c590647602712cd",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['title', 'label'],\n    num_rows: 45678\n})"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"실습에 사용되지 않는 불필요한 컬럼 제거\"\n",
    "removed_columns = ['guid', 'url', 'date']\n",
    "klue_tc_train = klue_tc_train.remove_columns(removed_columns)\n",
    "klue_tc_eval = klue_tc_eval.remove_columns(removed_columns)\n",
    "klue_tc_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.030196Z",
     "start_time": "2025-02-09T13:14:59.025910Z"
    }
   },
   "id": "97e781cc9076db48",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.031968Z",
     "start_time": "2025-02-09T13:14:59.030814Z"
    }
   },
   "id": "d6453b02f6044375",
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "source": [
    "카테고리를 확인하기 쉽게 label_str 컬럼 추가\n",
    "features 속성에서 label 컬럼을 확인하면 레이블id 와 카테고리를 연결할 수 있는 ClassLabel 객체가 있음\n",
    "해당 객체에는 Id를 카테고리로 변환하는 int2str 메서드가 있음\n",
    "- int2str(1): '경제' 카테고리 반환\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15007865df175699"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ClassLabel(names=['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치'], id=None)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_label = klue_tc_train.features['label']\n",
    "klue_tc_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.034519Z",
     "start_time": "2025-02-09T13:14:59.032443Z"
    }
   },
   "id": "710667457d542f76",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'경제'"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train.features['label'].int2str(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.037215Z",
     "start_time": "2025-02-09T13:14:59.035068Z"
    }
   },
   "id": "1fff71cbc517dd6b",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def make_str_label(batch):\n",
    "    batch['label_str'] = klue_tc_label.int2str(batch['label'])\n",
    "    return batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.039447Z",
     "start_time": "2025-02-09T13:14:59.037856Z"
    }
   },
   "id": "87323de41c434ae3",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "klue_tc_train = klue_tc_train.map(make_str_label, batched=True, batch_size=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.043197Z",
     "start_time": "2025-02-09T13:14:59.039972Z"
    }
   },
   "id": "6f36e08e689c9f06",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'title': ['유튜브 내달 2일까지 크리에이터 지원 공간 운영',\n  '어버이날 맑다가 흐려져…남부지방 옅은 황사',\n  '내년부터 국가RD 평가 때 논문건수는 반영 않는다',\n  '김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것',\n  '회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간'],\n 'label': [3, 3, 2, 2, 3],\n 'label_str': ['생활문화', '생활문화', '사회', '사회', '생활문화']}"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.045823Z",
     "start_time": "2025-02-09T13:14:59.043827Z"
    }
   },
   "id": "735d369e689fea72",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "45678"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(klue_tc_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.048101Z",
     "start_time": "2025-02-09T13:14:59.046392Z"
    }
   },
   "id": "b829947efcf874ca",
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 학습/검증/테스트 데이터셋 분할\n",
    "학습 데이터 중 10_000개만 추출해 사용, train_test_split() 메서드에 test_size를 입력하여 학습 데이터셋과 테스트 데이터셋으로 분리\n",
    "학습이 잘되고 있는지 확인할 검증 데이터와 성능 확엔에 사용할 테스트 데이터는 검증 데이터셋(klue_tc_eval)에서 각각 1000개씩 뽑아 사용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "314f3393a2c9e08c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = klue_tc_train.train_test_split(test_size=10_000, shuffle=True, seed=42)['test']\n",
    "dataset = klue_tc_eval.train_test_split(test_size=1000, shuffle=True, seed=42)\n",
    "\n",
    "test_dataset = dataset['test']\n",
    "valid_dataset = dataset['train'].train_test_split(test_size=1000, shuffle=True, seed=42)['test']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:14:59.055055Z",
     "start_time": "2025-02-09T13:14:59.048630Z"
    }
   },
   "id": "8cb0166d743194f0",
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trainer API\n",
    "\n",
    "허깅페이스는 학습에 필요한 다양한 기능(데이터로더 준비, 로깅, 평가, 저장 등)을 `TrainingArguments` 만으로 쉽게 활용할 수 있는 트레이너 API 제공"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad804a60f8cef74b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
