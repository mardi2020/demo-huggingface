{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19173f7c36dd5ed0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# torch 가 정상적으로 설치되었는지 확인하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74bffa931986d51c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # 설치된 PyTorch 버전 출력\n",
    "print(torch.cuda.is_available())  # GPU 사용 가능 여부 출력 (True면 GPU 사용 가능)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T07:25:49.412846Z",
     "start_time": "2025-02-09T07:25:48.694825Z"
    }
   },
   "id": "f702355005e7def2",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AutoModel 클래스로 id에 맞는 모델 가져오기\n",
    "\n",
    "model_id를 허깅페이스 모델 허브의 저장소 경로 혹은 로컬 경로 지정해서 모델 불러올 수 있다.\n",
    "RoBERTa는 구글의 BERT를 개선한 모델이고, 여기서 사용하는 모델은 RoBERTa 모델을 한국어로 학습한 모델이다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "645291d58f8ae7cc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "259f8ee22efa447691a32db683009273"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48684fcfca50435983db2eaee6fc35ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model_id = 'klue/roberta-base'\n",
    "model = AutoModel.from_pretrained(model_id)\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-09T07:26:35.038890Z",
     "start_time": "2025-02-09T07:25:51.151680Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AutoModel 클래스\n",
    "어떻게 `klue/roberta-base` 저장소의 모델이 RoBERTa 계열의 모델인지 알 수 있을까?\n",
    "- 허깅페이스 모델을 저장할 때 config.json 파일이 함께 저장되는데 해당 파일에는 model_type, 여러 설정 파라미터(num_attention_heads 등), 어휘 사전 크기(vocab_size), tokenizer_class 등이 저장됨\n",
    "\n",
    "AutoModel과 AutoTokenizer 클래스는 config.json을 참고해 적절한 모델과 토크나이저를 불러온다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de8a61ed3729d996"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 텍스트 분류 헤드가 붙은 모델 불러오기\n",
    "\n",
    "`SamLowe/roberta-base-go_emotions` 모델: 분류 헤드가 포함되어 있으며 입력 문장이 어떤 감성을 나타내는지 분류함(ex: admiration, amusement, anger etc...)\n",
    "`AutoModelForSequenceClassification`: 텍스트 시퀀스 분류를 위한 헤드가 포함된 모델을 불러올 때 사용하는 클래스"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea8a606fc2890898"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92d0b561f20c4811ae16e82544411ef1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a832c481f7a54d42a3c78af16dadaa40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_id = 'SamLowe/roberta-base-go_emotions'\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T07:35:43.746414Z",
     "start_time": "2025-02-09T07:34:56.087172Z"
    }
   },
   "id": "80b5e721682500c6",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 텍스트 분류를 위한 아키텍처에 모델 바디만 불러오기\n",
    "AutoModelForSequenceClassification 클래스를 사용하면 분류 헤드가 붙은 모델을 불러올 수 있다.\n",
    "이 클래스를 사용해 모델 바디 부분의 파라미터만 있는 `klue/roberta-base` 모델을 불러온다면, 아래와 같은 경고가 발생한다.\n",
    "- ⚠️경고 내용: 모델의 바디 부분은 `klue/roberta-base`의 사전학습된 파라미터를 불러왔으나 `klue/roberta-base` 모델 허브에서는 분류 헤드에 대한 파라미터를 찾을 수 없어 랜덤!!으로 초기화 했다는 내용\n",
    "- ⚠️분류 헤드가 랜덤으로 초기화되었기 때문에 그대로 사용하면 안되고 추가 학습 이후에 사용하라고 안내됨\n",
    "\n",
    "분류 헤드가 학습되지 않았기 때문에 의미 있는 분류를 할 수 없음, 그렇다면 어떻게 분류 헤드를 학습해 분류 모델을 만들 수 있을까?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "402119a4954a38b1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_id = 'klue/roberta-base'\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T07:38:59.098995Z",
     "start_time": "2025-02-09T07:38:58.491957Z"
    }
   },
   "id": "1fe4ed26e53691c0",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 토크나이저 활용\n",
    "\n",
    "⭐️토크나이저: 텍스트를 토큰 단위로 나누고 각 토큰을 대응하는 토큰 아이디로 변환, 필요한경우 특수 토큰을 추가하는 역할\n",
    "토크나이저도 학습 데이터를 통해 어휘 사전을 구축하므로 일반적으로 모델과 함께 저장됨\n",
    "\n",
    "허깅페이스 허브에서 모델과 토크나이저를 불러올때 동일한 모델 아이디로 맞춰야함!!\n",
    "\n",
    "- tokenizer_config.json: 토크나이저의 종류나 설정에 대한 정보를 갖고 있음\n",
    "- tokenizer.json: 실제 어휘 사전 정보를 갖고 있음"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "174f68fc1924e438"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4a4ceb80379409484de1b6c31431f5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2a0e2953ec44f3e8f8ad37cde6ed728"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb75d500997046318817046ccc062734"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "908c2482e1ae4acdb1fc72fddaf5e035"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = 'klue/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T07:46:07.173787Z",
     "start_time": "2025-02-09T07:46:04.116847Z"
    }
   },
   "id": "930f6de0dfde1900",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 토크나이저 예제\n",
    "\n",
    "tokenizer(\"문장\")\n",
    "- input_ids: 토큰 아이디의 리스트\n",
    "- attention_mask: 토큰이 실제 텍스트인지 아니면 길이를 맞추기 위해 추가한 padding인지 알려줌\n",
    "- token_type_ids: 토큰이 속한 문장의 아이디를 알려줌"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f773a1d3db1a801a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids [0, 9157, 7461, 2190, 2259, 8509, 2138, 1793, 2855, 5385, 2200, 20950, 2]\n",
      "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer(\"토크나이저는 텍스트를 토큰 단위로 나눈다\")\n",
    "\n",
    "for k, v in tokenized.items():\n",
    "    print(k, v)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:41:22.974664Z",
     "start_time": "2025-02-09T08:41:22.967425Z"
    }
   },
   "id": "806546eed13e77f8",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "- input_ids: 토큰화했을 때 각 토큰이 토크나이저 사전의 몇번째 항목인지 나타냄\n",
    "input_ids에서 첫번째 항목은 0이고 두번째 항목은 9157인데, 각각 [CLS]와 '토크'에 대응되는 것을 확인할 수 있음\n",
    "- attention_mask[idx] == 1: 실제 토큰 else 패딩\n",
    "\n",
    "token_type_ids[idx] == 0: 일반적으로 첫번째 문장임"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dd3d756ba68a227"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '토크', '##나이', '##저', '##는', '텍스트', '##를', '토', '##큰', '단위', '##로', '나눈다', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(tokenized['input_ids']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:39:35.525218Z",
     "start_time": "2025-02-09T08:39:35.522798Z"
    }
   },
   "id": "e0e1a52df42564e2",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "토큰 아이디를 다시 텍스트로 돌리고 싶다면 토크나이저의 `decode` 메서드 사용\n",
    "- 특수 토큰이 추가됨을 확인할 수 있음\n",
    "    - [CLS]\n",
    "    - [SEP]\n",
    "- skip_special_tokens=True 시 특수 토큰 스킵"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10de9890cd1db8bb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 토크나이저는 텍스트를 토큰 단위로 나눈다 [SEP]\n",
      "토크나이저는 텍스트를 토큰 단위로 나눈다\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized['input_ids']))\n",
    "print(tokenizer.decode(tokenized['input_ids'], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:41:29.768570Z",
     "start_time": "2025-02-09T08:41:29.765068Z"
    }
   },
   "id": "dee1d24ce9acce0e",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[0, 5891, 2205, 5971, 35, 2], [0, 13472, 10211, 2036, 16, 30520, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이저에 여러 문장을 넣을수도 있다.\n",
    "tokenizer(['안녕하세요?', 'Hello, world'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:42:18.641479Z",
     "start_time": "2025-02-09T08:42:18.636246Z"
    }
   },
   "id": "405e5256536b04bf",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "한 번에 여러 문장을 모델에 넣어야 하는 경우가 있음\n",
    "\n",
    "예를 들어, 2개의 문장이 서로 원인/결과 관계인지 학습시키고 싶을 때\n",
    "- 이 경우, 2개의 문장이 하나의 데이터라는 것을 표시하기 위해 아래처럼 리스트로 한번 더 감싼다"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1007bc699f68c58d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[0, 5891, 2205, 5971, 35, 2, 13472, 10211, 2036, 16, 30520, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([['안녕하세요?', 'Hello, world']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T08:43:46.435261Z",
     "start_time": "2025-02-09T08:43:46.430895Z"
    }
   },
   "id": "4530ef09b87152e1",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "tokenizer의 batch_decode() 메서드\n",
    "- input_ids 부분의 토큰 아이디를 문자열로 복원\n",
    "- 2개의 문장을 한번에 토큰화할 경우, [SEP]으로 두 문장을 구분함\n",
    "- 특수 토큰은 모델의 아키텍처에 따라 달라질 수 있음"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9453474e9852acc6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS] 첫번째 문장 [SEP]', '[CLS] 두번째 문장 [SEP]']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_tokenized_result = tokenizer(['첫번째 문장', '두번째 문장'])['input_ids']\n",
    "tokenizer.batch_decode(first_tokenized_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T09:47:05.406199Z",
     "start_time": "2025-02-09T09:47:05.401255Z"
    }
   },
   "id": "f2d3397469550087",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS] 첫번째 문장 [SEP] 두번째 문장 [SEP]']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_tokenized_result = tokenizer([['첫번째 문장', '두번째 문장']])['input_ids']\n",
    "tokenizer.batch_decode(second_tokenized_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T09:47:35.344728Z",
     "start_time": "2025-02-09T09:47:35.340796Z"
    }
   },
   "id": "9d9cfb98173e94c1",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "### token_type_ids: 문장을 구분하는 역할\n",
    "\n",
    "BERT는 학습할때 2개의 문장이 서로 이어지는지 맞추는 NST(Next Sentence prediction) 작업을 활용, 이를 위해 문장을 구분하는 토큰 타입 아이디를 만듦\n",
    "그래서 BERT의 토크나이저를 불러오면, 문장에 따라 토큰 타입 아이디를 구분함\n",
    "\n",
    "klue/bert-base 토크나이저를 사용하면 첫번째 문장의 토큰 타입 아이디는 0, 두번째 문장의 토큰 타입 아이디는 1\n",
    "klue/roberta-base의 경우, 모두 0임 -> RoBERTa 계열 모델은 NSP 작업을 학습 과정에서 제거해서 문장 토큰 구분이 필요없다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e77e4007e8879eb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a354ae2b32c427d8d0eee02ae30d048"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa2574eeaf1b45b89813b783c4b63190"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60ed8a35531b419cbfbab167bd3ef432"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad29620bc8f745c8871a61221cba36fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bb9a5cd45f54e888285cd2913ba0f05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'input_ids': [[2, 1656, 2517, 3135, 6265, 3, 864, 2517, 3135, 6265, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "bert_tokenizer([['첫번째 문장', '두번째 문장']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T09:51:03.317315Z",
     "start_time": "2025-02-09T09:51:00.065527Z"
    }
   },
   "id": "2d870729e743620e",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[0, 1656, 2517, 3135, 6265, 2, 864, 2517, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
    "roberta_tokenizer([['첫번째 문장', '두번째 문장']]) # token_type_ids 가 모두 0 이다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T09:51:32.760078Z",
     "start_time": "2025-02-09T09:51:32.517388Z"
    }
   },
   "id": "d08914371d1929b8",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1ae559df69848829e598fb7f53d249e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24e0199bb4974eb781883a45afc5281c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5cfb7666fb8f48dbbd046d84c7e88188"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2dee1b37d874407f839d1756178e2225"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63459846a0fc4ce9a782c42903325c2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'input_ids': [[0, 9502, 3645, 2, 2, 10815, 3645, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1]]}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roberta-base 토크나이저로 영어 문장을 토큰화하면 결과에 token_type_ids 항목이 없다.\n",
    "en_roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "en_roberta_tokenizer([['first sentence', 'second sentence']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T09:52:38.481750Z",
     "start_time": "2025-02-09T09:52:34.225285Z"
    }
   },
   "id": "33d79b26379a8df1",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "### attention_mask\n",
    "> 해당 토큰이 패딩 토큰인지 실제 데이터인지에 대한 정보를 담음\n",
    "\n",
    "패딩: 모델에 입력하는 토큰 아이디의 길이를 맞추기 위해 추가하는 특수 토큰\n",
    "- tokenizer의 padding='longest' 를 입력하면 입력한 문장 중 가장 긴 문장에 맞춰 패딩 토큰 추가"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16c2f70c23289ed"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [[0, 1656, 1141, 3135, 6265, 2073, 1599, 2062, 18, 2, 1, 1, 1, 1, 1, 1, 1], [0, 864, 1141, 3135, 6265, 2073, 1656, 1141, 3135, 6265, 2178, 2062, 831, 647, 2062, 18, 2]]\n",
      "token_type_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "두 번째 문장이 더 길기 때문에 더 긴 문장에 맞춰 패딩 토큰을 추가한다면 첫 번째 문장에 패딩이 추가됨\n",
    "input_ids에서 첫 번째 문장에 패딩 토큰(토큰 아이디 = 1)이 6개 추가됨\n",
    "attention_mask에는 패딩 토큰을 나타내는 숫자 0이 6개 붙음\n",
    "\"\"\"\n",
    "result = tokenizer(['첫 번째 문장은 짧다.', '두 번째 문장은 첫 번째 문장보다 더 길다.'], padding='longest')\n",
    "for k, v in result.items():\n",
    "    print(f'{k}: {v}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T09:58:34.607854Z",
     "start_time": "2025-02-09T09:58:34.605356Z"
    }
   },
   "id": "d58bf818fbbc2f32",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "# datasets 라이브러리 활용하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9177de07ed335627"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "README.md:   0%|          | 0.00/22.5k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4741b22b1bee4eb4a649fa6014898435"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "train-00000-of-00001.parquet:   0%|          | 0.00/21.4M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c98c5cd7cbd47bf98379397882e879a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "validation-00000-of-00001.parquet:   0%|          | 0.00/8.68M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34c66ccd354945978ea7ce9ecf15d915"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/17554 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4dc0529e530c46bd9e353e7eb4fce7a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating validation split:   0%|          | 0/5841 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2256b6c1cf24e2c973277f21c381d25"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load_dataset(): 데이터셋을 불러오는 함수(데이터셋 이름, 서브셋 이름)\n",
    "klue_mrc_dataset = load_dataset('klue', 'mrc')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T10:00:17.280901Z",
     "start_time": "2025-02-09T10:00:00.524904Z"
    }
   },
   "id": "1aa38af0e461d66c",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n        num_rows: 17554\n    })\n    validation: Dataset({\n        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n        num_rows: 5841\n    })\n})"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_mrc_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T10:00:20.504765Z",
     "start_time": "2025-02-09T10:00:20.501594Z"
    }
   },
   "id": "2df512d7247e3e19",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
      "    num_rows: 17554\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 유형이 train인 데이터만 보고 싶은 경우\n",
    "print(load_dataset('klue', 'mrc', split='train'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:43:22.790588Z",
     "start_time": "2025-02-09T12:43:16.258820Z"
    }
   },
   "id": "293159ae99de3975",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 로컬의 데이터를 활용하는 법"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fd7a0a904441263"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# local의 csv - 로컬에 해당 데이터가 없어서 오류남 주석처리\n",
    "# dataset = load_dataset('csv', data_files=\"file.csv\")\n",
    "\n",
    "# 파이썬 딕셔너리 \n",
    "my_dict = {\"a\": [1, 2, 3]}\n",
    "dataset2 = Dataset.from_dict(my_dict)\n",
    "\n",
    "# 판다스 데이터프레임\n",
    "import  pandas as pd\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3]})\n",
    "dataset3 = Dataset.from_pandas(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:45:54.866898Z",
     "start_time": "2025-02-09T12:45:54.856171Z"
    }
   },
   "id": "2cc1084d7f442c2",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['a'],\n    num_rows: 3\n})"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:45:59.964799Z",
     "start_time": "2025-02-09T12:45:59.962212Z"
    }
   },
   "id": "1b2e2fe0273b4e6",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['a'],\n    num_rows: 3\n})"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:46:02.371535Z",
     "start_time": "2025-02-09T12:46:02.368724Z"
    }
   },
   "id": "335c5c3c9b3c5e84",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 학습시키기\n",
    "한국어 기사 제목을 바탕으로 기사의 카테고리를 분류하는 텍스트 분류 모델 실습\n",
    "\n",
    "✨과정\n",
    "1. 데이터셋 준비\n",
    "2. 모델과 토크나이저를 불러와 모델 학습 - 허깅페이스 트랜스포머에서는 학습 과정을 추상화한 Trainer API를 제공(but, 내부 과정을 알 수 없음)\n",
    "3. 학습을 마친 모델을 저장하거나 공유할 수 있도록 허깅페이스 허브에 업로드"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "833bef10f20e71b7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "train-00000-of-00001.parquet:   0%|          | 0.00/4.17M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "573f278e1be24b50a69be841508002f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "validation-00000-of-00001.parquet:   0%|          | 0.00/847k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "615d6af4ef8146e49816733f1102c8dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/45678 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dc2d159c18640cda850725ded0bfc49"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating validation split:   0%|          | 0/9107 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cff4a93302304e08947ca677943091b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['guid', 'title', 'label', 'url', 'date'],\n    num_rows: 45678\n})"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"klue 데이터셋의 YNAT(연합 뉴스 기사 제목과 기사가 속한 카테고리 정보 포함) 서브셋 활용\"\n",
    "KLUE, MNC = 'klue', 'ynat'\n",
    "\n",
    "klue_tc_train = load_dataset(KLUE, MNC, split='train')\n",
    "klue_tc_eval = load_dataset(KLUE, MNC, split='validation')\n",
    "klue_tc_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:51:23.841682Z",
     "start_time": "2025-02-09T12:51:08.422463Z"
    }
   },
   "id": "e4aa321303da497e",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['guid', 'title', 'label', 'url', 'date'],\n    num_rows: 9107\n})"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "guid: 데이터의 고유 ID - 불필요\n",
    "title\n",
    "label: 속한 카테고리 ID\n",
    "url - 불필요\n",
    "date - 불필요\n",
    "\"\"\"\n",
    "klue_tc_eval"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:54:02.895123Z",
     "start_time": "2025-02-09T12:54:02.892525Z"
    }
   },
   "id": "be9f8aad35254af1",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'guid': 'ynat-v1_train_00000',\n 'title': '유튜브 내달 2일까지 크리에이터 지원 공간 운영',\n 'label': 3,\n 'url': 'https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=105&sid2=227&oid=001&aid=0008508947',\n 'date': '2016.06.30. 오전 10:36'}"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:51:45.996842Z",
     "start_time": "2025-02-09T12:51:45.992736Z"
    }
   },
   "id": "beb2c300d207d289",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치']"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"데이터셋의 정보를 저장하고 있는 features 속성에서 label 컬럼의 항목별 이름 확인\"\n",
    "klue_tc_train.features['label'].names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:53:41.147374Z",
     "start_time": "2025-02-09T12:53:41.143553Z"
    }
   },
   "id": "8c590647602712cd",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['title', 'label'],\n    num_rows: 45678\n})"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"실습에 사용되지 않는 불필요한 컬럼 제거\"\n",
    "removed_columns = ['guid', 'url', 'date']\n",
    "klue_tc_train = klue_tc_train.remove_columns(removed_columns)\n",
    "klue_tc_eval = klue_tc_eval.remove_columns(removed_columns)\n",
    "klue_tc_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:54:57.348075Z",
     "start_time": "2025-02-09T12:54:57.343157Z"
    }
   },
   "id": "97e781cc9076db48",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d6453b02f6044375"
  },
  {
   "cell_type": "markdown",
   "source": [
    "카테고리를 확인하기 쉽게 label_str 컬럼 추가\n",
    "features 속성에서 label 컬럼을 확인하면 레이블id 와 카테고리를 연결할 수 있는 ClassLabel 객체가 있음\n",
    "해당 객체에는 Id를 카테고리로 변환하는 int2str 메서드가 있음\n",
    "- int2str(1): '경제' 카테고리 반환\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15007865df175699"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ClassLabel(names=['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치'], id=None)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_label = klue_tc_train.features['label']\n",
    "klue_tc_label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:58:28.752240Z",
     "start_time": "2025-02-09T12:58:28.749069Z"
    }
   },
   "id": "710667457d542f76",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'경제'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train.features['label'].int2str(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:57:16.991034Z",
     "start_time": "2025-02-09T12:57:16.988381Z"
    }
   },
   "id": "1fff71cbc517dd6b",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def make_str_label(batch):\n",
    "    batch['label_str'] = klue_tc_label.int2str(batch['label'])\n",
    "    return batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:58:32.665732Z",
     "start_time": "2025-02-09T12:58:32.663546Z"
    }
   },
   "id": "87323de41c434ae3",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/45678 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2fd33ceb1e44cd79ec156bbf4c4745c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "klue_tc_train = klue_tc_train.map(make_str_label, batched=True, batch_size=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T12:58:49.901480Z",
     "start_time": "2025-02-09T12:58:49.845382Z"
    }
   },
   "id": "6f36e08e689c9f06",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'title': ['유튜브 내달 2일까지 크리에이터 지원 공간 운영',\n  '어버이날 맑다가 흐려져…남부지방 옅은 황사',\n  '내년부터 국가RD 평가 때 논문건수는 반영 않는다',\n  '김명자 신임 과총 회장 원로와 젊은 과학자 지혜 모을 것',\n  '회색인간 작가 김동식 양심고백 등 새 소설집 2권 출간'],\n 'label': [3, 3, 2, 2, 3],\n 'label_str': ['생활문화', '생활문화', '사회', '사회', '생활문화']}"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:03:35.805460Z",
     "start_time": "2025-02-09T13:03:35.802240Z"
    }
   },
   "id": "735d369e689fea72",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "45678"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(klue_tc_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:03:45.601653Z",
     "start_time": "2025-02-09T13:03:45.598600Z"
    }
   },
   "id": "b829947efcf874ca",
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 학습/검증/테스트 데이터셋 분할\n",
    "학습 데이터 중 10_000개만 추출해 사용, train_test_split() 메서드에 test_size를 입력하여 학습 데이터셋과 테스트 데이터셋으로 분리\n",
    "학습이 잘되고 있는지 확인할 검증 데이터와 성능 확엔에 사용할 테스트 데이터는 검증 데이터셋(klue_tc_eval)에서 각각 1000개씩 뽑아 사용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "314f3393a2c9e08c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = klue_tc_train.train_test_split(test_size=10_000, shuffle=True, seed=42)['test']\n",
    "dataset = klue_tc_eval.train_test_split(test_size=1000, shuffle=True, seed=42)\n",
    "\n",
    "test_dataset = dataset['test']\n",
    "valid_dataset = dataset['train'].train_test_split(test_size=1000, shuffle=True, seed=42)['test']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-09T13:04:39.921156Z",
     "start_time": "2025-02-09T13:04:39.904364Z"
    }
   },
   "id": "8cb0166d743194f0",
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trainer API\n",
    "\n",
    "허깅페이스는 학습에 필요한 다양한 기능(데이터로더 준비, 로깅, 평가, 저장 등)을 `TrainingArguments` 만으로 쉽게 활용할 수 있는 트레이너 API 제공"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad804a60f8cef74b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f63822665d401803"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
